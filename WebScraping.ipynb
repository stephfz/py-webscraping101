{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMI7H2xbP+gGirsyncg35EZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephfz/py-webscraping101/blob/master/WebScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSYN-4yYZlbM"
      },
      "source": [
        "# AboutMe\n",
        "\n",
        "**Stephanie Frias**  [@\\_stephfz\\_](https://twitter.com/_stephfz_)\n",
        "\n",
        "\n",
        "*   Ingeniera de Software üë©‚Äçüíª\n",
        "*   Sr. SDET @ Evernote üêò\n",
        "*   Peruana üáµüá™\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZkTP8d7kddK"
      },
      "source": [
        "# Web Scraping con python\n",
        "\n",
        "¬øQu√© es webscraping?\n",
        "Es la extracci√≥n de data que podemos encontrar en alguna website\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhPiO_k2ezYv"
      },
      "source": [
        "## ¬øC√≥mo funciona un web scraper?\n",
        "Un web scraper toma una url determinada y \"se carga\" todo el contenido HTML. Es por esto que s√∫per importante entender a full HTML y conocer de css ya que podremos iniciar la extraccion indicandole al scraper en que etiquetas o nodos encontrar√° la data que le requerimos. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9VXURQil7qJ"
      },
      "source": [
        "# ¬øQu√© vamos a emplear?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvht7i7LZqMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d64e59-5fcf-4a19-e55c-68d8800d62b2"
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsNFJbqlaJUh"
      },
      "source": [
        "!pip install requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEg6a5e8bIVU"
      },
      "source": [
        "# Web Scraping de Webs Est√°ticas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDofC-eVj5xI"
      },
      "source": [
        "## \"Cargando\" la pagina"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTGDLtwvaLnl"
      },
      "source": [
        "import requests\n",
        "import pprint\n",
        "\n",
        "URL = 'https://www.buscalibre.cl/libros/search?q=bailarina'\n",
        "page = requests.get(URL)\n",
        "pprint.pprint(page.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiLWARHwvmRe"
      },
      "source": [
        "## Extrayendo un _SOLO_ elemento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI-TtwTXawfW"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "#buscamos todos los elementos que esten marcados con las clase producto \n",
        "results = soup.find_all('div',class_='producto')\n",
        "print(len(results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM1j_r5_dBCV"
      },
      "source": [
        "# tambien podemos todos los resultados\n",
        "print(soup.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5ergiM7gXRy"
      },
      "source": [
        "print(results[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGSfoC8vy_Ww"
      },
      "source": [
        "**Obteniendo un valor por etiqueta dentro de un elemento de la sopa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTR4_bwAdGS-"
      },
      "source": [
        "element = results[2] \n",
        "book_title = element.find('a')['title']\n",
        "print(book_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7QVq2LrVm8v"
      },
      "source": [
        "**Obteniendo el Autor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uetlhV9mVorh"
      },
      "source": [
        "element.find('div',class_='autor').text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH3citJ9AlLY"
      },
      "source": [
        "**Obteniendo Atributos custom**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKE5KI6wgZ2-"
      },
      "source": [
        "print(element['data-precio'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsZimRUDGXJ"
      },
      "source": [
        "**Obteniendo data de un elemento anidado**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIk3UjSxDMJz"
      },
      "source": [
        "print(element.find_all('div', class_='descuento-v2')[0].text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRoiiepDJfiB"
      },
      "source": [
        "import requests\n",
        "URL = 'https://www.buscalibre.cl/libros/search?q=bailarina&page=100'\n",
        "response = requests.get(URL)\n",
        "not_found = 'Lo sentimos, pero no encontramos lo que buscas'\n",
        "print(response.status_code)\n",
        "print (not_found in response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VFC-s_rDODj"
      },
      "source": [
        "**Juntando todo y a obtener los datos de todos los resultados**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brfgC8CXHbWB"
      },
      "source": [
        "titles = []\n",
        "prices = []\n",
        "discounts = []\n",
        "authors  = []\n",
        "\n",
        "not_found_msg = 'Lo sentimos, pero no encontramos lo que buscas'\n",
        "URL = 'https://www.buscalibre.cl/libros/search?q=bailaira&page='\n",
        "pag_index = 1\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "while (True):\n",
        "  URL = 'https://www.buscalibre.cl/libros/search?q=bailarina&page={0}'.format(pag_index)\n",
        "  response = requests.get(URL)\n",
        "  if (not_found_msg not in response.text):\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    #buscamos todos los elementos que esten marcados con las clase producto \n",
        "    results = soup.find_all('div',class_='producto')\n",
        "    for element in results:\n",
        "      titles.append(element.find('a')['title'])\n",
        "      authors.append(element.find('div',class_='autor').text)\n",
        "      prices.append(element['data-precio'])\n",
        "      discounts.append(element.find_all('div', class_='descuento-v2')[0].text)\n",
        "    pag_index+= 1\n",
        "  else:\n",
        "    break;    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPESxNYsqqKM"
      },
      "source": [
        "print(titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCSAxGlEPJGE"
      },
      "source": [
        "import pandas as pd\n",
        "data = {'title' : titles, 'author':authors, 'price':prices, 'dscto':discounts}\n",
        "df = pd.DataFrame(data)\n",
        "df.tail(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1y6Ed64u8Gc"
      },
      "source": [
        "# remover el % de la columan dscto\n",
        "df['dscto'] = df['dscto'].apply(lambda x : x[:x.find('%dcto'):])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bufcl7O20NKm"
      },
      "source": [
        "# Web Scraping con Webs Din√°micas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qqc7-o4j_l2"
      },
      "source": [
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUzUYRoYjwl2"
      },
      "source": [
        "\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "#datos a ingresar\n",
        "modelo = \"Alfa-Romeo\"\n",
        "annio_fabricacion = \"2022-Nuevo\"\n",
        "modelo = \"147 1.6 TI\"\n",
        "telefono_cotizante = \"997261789\"\n",
        "email_cotizante = \"mimail@yahoo.com\"\n",
        "edad_cotizante = \"38\"\n",
        "##\n",
        "\n",
        "\n",
        "driver.get(\"http://www.segurosimple.com/\")\n",
        "\n",
        "element = driver.find_element(\"id\", \"Marca\")\n",
        "element.send_keys(modelo)\n",
        "\n",
        "\n",
        "element = driver.find_element(\"id\",\"A√±o\")\n",
        "element.send_keys(annio_fabricacion)\n",
        "\n",
        "\n",
        "element = driver.find_element(By.ID,\"Modelo\")\n",
        "assert len(element.text) > len(\":: Seleccione ::\"), \\\n",
        "        \"Los modelos de la marca %s no fueron cargados\" % modelo\n",
        "element.send_keys(modelo)\n",
        "\n",
        "driver.find_element(By.ID,\"TelefonoCotizacion\").send_keys(telefono_cotizante)\n",
        "\n",
        "element = driver.find_element(By.ID,\"EmailCotizacion\")\n",
        "element.send_keys(email_cotizante)\n",
        "\n",
        "element = driver.find_element(By.ID,\"edadUsuario\")\n",
        "element.send_keys(edad_cotizante)\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "btn = driver.find_element(\"id\",\"boton-cotizar\")\n",
        "driver.execute_script(\"arguments[0].click();\",btn)\n",
        "\n",
        "# Mala practica\n",
        "#time.sleep(20)\n",
        "driver.implicitly_wait(20)\n",
        "try:\n",
        "    element = driver.find_element(By.ID, \"btCotizarOtroVehiculo\")\n",
        "    print(element)\n",
        "    source = driver.page_sourc\n",
        "except NoSuchElementException as e:\n",
        "    print(e)\n",
        "\n",
        "print(driver.page_source)  # results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k3VUoShlEfm"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "page_source = source #driver.page_source\n",
        "soup = BeautifulSoup(page_source, 'lxml')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYFtlhFHmKBJ"
      },
      "source": [
        "container = soup.find(\"div\",{\"id\":'CompadadorResultadoDesktop'}) \n",
        "rows = container.findAll('tr')\n",
        "for row in rows:\n",
        "  broker_img, broker_price = None, None\n",
        "  broker_img = (row.find_all('td')[0]).find('img')\n",
        "  if broker_img != None:\n",
        "    broker_name = (broker_img['alt'])\n",
        "    broker_price = (row.find_all('td')[1]).find('h3')\n",
        "    if broker_price != None:\n",
        "      broker_price = (broker_price.text)\n",
        "    print (broker_name,broker_price)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS3u9HIT1AHw"
      },
      "source": [
        "# Recursos √ötiles\n",
        "* [Gu√≠a de inicio de Beautiful Soup](https://j2logo.com/python/web-scraping-con-python-guia-inicio-beautifulsoup/)\n",
        "* [Selectores CSS](https://flukeout.github.io/)\n",
        "* [Primeros para pasos con Selenium, ejemplos con python](https://realpython.com/modern-web-automation-with-python-and-selenium)"
      ]
    }
  ]
}